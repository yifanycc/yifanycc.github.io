<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title></title>
</head>
<body>
<script type="text/javascript">

var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
try {
    var pageTracker = _gat._getTracker("UA-130203500-1");
    pageTracker._trackPageview();
} catch(err) {}</script>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Yifan Yang</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="repositories.html">Repositories</a></div>
<!--<div class="menu-category">Research</div>-->
<!--<div class="menu-item"><a href="publications.html">Publications</a></div>-->
<!--<div class="menu-category">Teaching</div>-->
<!--<div class="menu-item"><a href="courses.html">Courses</a></div>-->
</td>
<td id="layout-content">
<h1>Yifan Yang</h1>
<table class="imgtable"><tr><td>
<img src="/profile.png" alt="Self" width="120px" />&nbsp;</td>
<td align="left"><p>PhD Candidate <br />
Department of Computer Science <br />
University of California, Santa Barbara (UCSB)<br />
Email: yifanyang at ucsb dot edu <br />
<a href="https://scholar.google.com/citations?user=PX2IQxsAAAAJ&amp;hl=en">Google Schoolar</a>&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.linkedin.com/in/yifan-yang-baa4a5138/">Linkedin</a></p>
</td></tr></table>
  <br />
<p><span style="color: red;"><b>I'm actively looking for a 2025 summer internship (both research and ML engineer) focused on LLM efficiency and general applications. I'm also interested in full-time positions starting in 2026. Feel free to reach out and keep in touch for future opportunities!</b></span></p>
<h2>About me</h2>
<p>I am a PhD candidate in UCSB computer science department. Prior to UCSB, I received my B.S.
  in Electronic and Information Engineering from Huazhong University of Science and Technology (HUST).
Currently, I'm working on the efficient training/inference of Large Language Models (LLMs), including but not limited to the
  parameter efficient fine-tuning (PEFT), model compression (weight decomposition and pruning), quantization, zeroth-order optimization and robustness
  issue during the efficient training. Before summer 2023, I worked on the optimization theory.</p>
<h2>News</h2>
  <p>04/21/2024: Our paper 'AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning' is accepted by EMNLP 2024. </p>
  <p>04/21/2024: Our paper 'LoRETTA: Low-Rank Economic Tensor-Train Adaptation for Ultra-Low-Parameter Fine-Tuning of
    Large Language Models' is selected as an oral presentation paper (top 5%) by NAACL 2024. </p>
  <p>03/28/2024: Our paper 'PID Control-Based Self-Healing to Improve the Robustness of Large Language Models' is accepted by TMLR. </p>
  <p>03/13/2024: Our paper 'LoRETTA: Low-Rank Economic Tensor-Train Adaptation for Ultra-Low-Parameter Fine-Tuning of
    Large Language Models' is accepted by NAACL 2024. </p>
 <p>03/08/2024: I will join Amazon AGI for my summer internship, working on the inference speed-up of LLMs. </p>
   <p>08/01/2023: I start working in the field of Natural Language Processing, focusing on the efficient training of LLMs. </p>
<h2>Industrial Experience</h2>
  <p><b>Amazon AGI</b>, Applied Scientist Intern (Inclined), Pittsburgh, PA, June 2024 - Sep 2024</p>
  Working on low-degradation pruning method for inference speed up of large scale LLMs
<h2>Preprint</h2>
  Yifan Yang, Kai Zhen, Denis Filimonov, Markus Müller, Jonas M. Kübler, Rupak Vignesh Swaminathan, Nathan Susanj, Zheng Zhang, Athanasios Mouchtaris, "Wanda++: Pruning Large Language Models via Regional Gradients", under review for NAACL 25, to be released.
  <p><p>
  Sajjad Ghiasvand, Yifan Yang, Zhiyu Xue, Mahnoosh Alizadeh, Zheng Zhang, Ramtin Pedarsani, "Communication-Efficient and Tensorized Federated Fine-Tuning of
Large Language Models", under review for NAACL 25. <a href="https://arxiv.org/pdf/2410.13097.pdf"> [arxiv]</a>,
  <p><p>
   Yifan Yang, Alec Koppel, Zheng Zhang, "A Gradient-based Approach for Online Robust Deep Neural Network Training with Noisy Labels".
   <a href="https://arxiv.org/abs/2306.05046.pdf"> [arxiv]</a>
<p><p>
   Yifan Yang, Chang Liu, Zheng Zhang, "Particle-based Online Bayesian Sampling", submitting to Transactions on Machine Learning Research (TMLR).
   <a href="https://arxiv.org/pdf/2302.14796.pdf"> [arxiv]</a>
<h2>Publications</h2>
    Yifan Yang, Kai Zhen, Ershad Banijamal, Athanasios Mouchtaris, Zheng Zhang, "AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning", in Proceedings of
    2024 Conference on Empirical Methods in Natural Language Processing (EMNLP 2024),  Miami, USA, 2024.
  <a href="https://arxiv.org/abs/2406.18060.pdf"> [arxiv]</a>
<p><p>
Zhuotong Chen, Zihu Wang, Yifan Yang, Qianxiao Li, Zheng Zhang, "PID Control-Based Self-Healing to Improve the
    Robustness of Large Language Models", in Transactions on Machine Learning Research (TMLR), 2024.
<p><p>
   Yifan Yang, Jiajun Zhou, Ngai Wong, Zheng Zhang, "LoRETTA: Low-Rank Economic Tensor-Train Adaptation for
Ultra-Low-Parameter Fine-Tuning of Large Language Models", in Proceedings of
    2024 Annual Conference of the North American Chapter of the Association for Computational
    Linguistics (NAACL 2024), <b>Oral, top 5%</b>,  Mexico City, Mexico, 2024.<a href="https://arxiv.org/pdf/2402.11417.pdf"> [arxiv]</a><a href="https://github.com/yifanycc/loretta"> [code]</a>
<p><p>
      Yifan Yang, Lin Chen, Pan Zhou, Xiaofeng Ding, "Vflh: A Following-the-Leader-History Based Algorithm for Adaptive
    Online Convex Optimization with Stochastic Constraints", to appear in Proceedings of the 35th IEEE International
    Conference on Tools with Artificial Intelligence, Atlanta, USA, 2023. <b>(Best Student Paper Award, top 1%)</b>
   <p><p>
          Yifan Yang, Jie Xu, Zichuan Xu, Pan Zhou and Tie Qiu, "Quantile context-aware social IoT big data recommendation
    with D2D communication", IEEE Internet of Things Journal 7.6 (2020): 5533-5548.
    <div id="footer">
<div id="footer-text">
Page updated 09/20/2024.
<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=080808&w=200&t=n&d=AjYkGYhqfkljujHmVZFqGgw6WAoh_pTfdnSPzeqxwcE&co=ffffff&cmo=3acc3a&cmn=ff5353&ct=808080'></script>
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
